{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe10982-c65c-4e49-b13d-cfca3d98db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat, os, re\n",
    "\n",
    "def pre_validate_cnn(notebook_path, folder_name):\n",
    "    try:\n",
    "        nb = nbformat.read(notebook_path, as_version=4)\n",
    "    except Exception:\n",
    "        return (\"FAIL\", \"Error or corrupted notebook - cannot be opened\", 0)\n",
    "\n",
    "    # BITS ID from filename\n",
    "    bits_id_from_filename = os.path.basename(notebook_path).split(\"_\")[0]\n",
    "\n",
    "    # BITS ID from notebook (search all cell types: RNN uses code-cell docstrings)\n",
    "    bits_id_from_notebook = None\n",
    "    for cell in nb.cells:\n",
    "        match = re.search(r\"202\\d[A-Z]{2}\\d{5}\", cell.source.upper())\n",
    "        if match:\n",
    "            bits_id_from_notebook = match.group(0)\n",
    "            break\n",
    "\n",
    "    if not bits_id_from_notebook:\n",
    "        return (\"FAIL\", \"BITS ID not found in notebook\", 0)\n",
    "\n",
    "    if bits_id_from_filename.upper() != bits_id_from_notebook:\n",
    "        return (\"FAIL\", \"Filename does not match BITS ID inside notebook\", 0)\n",
    "\n",
    "    # Student name (search all cell types: RNN uses code-cell docstrings)\n",
    "    student_name = None\n",
    "    for cell in nb.cells:\n",
    "        for line in cell.source.split(\"\\n\"):\n",
    "            if line.lower().strip().startswith(\"name\"):\n",
    "                student_name = line.split(\":\", 1)[1].strip()\n",
    "                break\n",
    "        if student_name:\n",
    "            break\n",
    "\n",
    "    if folder_name.lower() != student_name.lower():\n",
    "        print(student_name.lower())\n",
    "        print(folder_name.lower())\n",
    "        return (\"FAIL\", \"Folder name does not match student name in notebook\", 0)\n",
    "\n",
    "    # Execution check\n",
    "    if not any(c.cell_type == \"code\" and c.get(\"outputs\") for c in nb.cells):\n",
    "        return (\"FAIL\", \"All outputs cleared - notebook not executed\", 0)\n",
    "\n",
    "    for cell in nb.cells:\n",
    "        for out in cell.get(\"outputs\", []):\n",
    "            if out.output_type == \"error\":\n",
    "                return (\"FAIL\", \"Notebook contains execution errors\", 0)\n",
    "\n",
    "    return (\"PASS\", \"Pre-validation successful\", \"Proceed to grading\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b2c09d-63b4-4aa5-b1f0-e4ee1e9debe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PASS', 'Pre-validation successful', 'Proceed to grading')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input: RNN assignment notebook (run from project root: bits-mtech-assignment)\n",
    "notebook_path = \"2025AA05387_RNN_assignment.ipynb\"\n",
    "folder_name = \"SHELAR SACHIN KRISHNA\"  # must match Name: in notebook for validation\n",
    "\n",
    "pre_validate_cnn(notebook_path, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe4c264-c5d5-49ac-982c-25104991116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "import os, re, json\n",
    "\n",
    "# ============================================================\n",
    "# ------------------- HELPER FUNCTIONS -----------------------\n",
    "# ============================================================\n",
    "\n",
    "def extract_all_source_code(nb):\n",
    "    return \"\\n\".join(\n",
    "        cell.source for cell in nb.cells if cell.cell_type == \"code\"\n",
    "    )\n",
    "\n",
    "def extract_json_output(nb):\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == \"code\":\n",
    "            for out in cell.get(\"outputs\", []):\n",
    "                if isinstance(out, dict) and \"text\" in out:\n",
    "                    try:\n",
    "                        return json.loads(out[\"text\"])\n",
    "                    except:\n",
    "                        pass\n",
    "    return None\n",
    "\n",
    "def extract_analysis_from_markdown(nb):\n",
    "    text = \"\"\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == \"markdown\":\n",
    "            text += \" \" + cell.source\n",
    "    return text\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def extract_numbers(text):\n",
    "    return [int(x) for x in re.findall(r\"\\d+\", text)]\n",
    "\n",
    "# ============================================================\n",
    "# --------------- PRE_VALIDATION_CHECK_CNN -------------------\n",
    "# ============================================================\n",
    "\n",
    "def pre_validate_cnn(notebook_path, folder_name):\n",
    "    try:\n",
    "        nb = nbformat.read(notebook_path, as_version=4)\n",
    "    except Exception:\n",
    "        return False, \"Error or corrupted notebook - cannot be opened\", 0\n",
    "\n",
    "    # BITS ID from filename\n",
    "    bits_id_filename = os.path.basename(notebook_path).split(\"_\")[0]\n",
    "\n",
    "    # BITS ID from notebook (search all cell types: RNN uses code-cell docstrings)\n",
    "    bits_id_notebook = None\n",
    "    for cell in nb.cells:\n",
    "        match = re.search(r\"202\\d[A-Z]{2}\\d{5}\", cell.source.upper())\n",
    "        if match:\n",
    "            bits_id_notebook = match.group(0)\n",
    "            break\n",
    "\n",
    "    if not bits_id_notebook:\n",
    "        return False, \"BITS ID not found in notebook\", 0\n",
    "\n",
    "    if bits_id_filename.upper() != bits_id_notebook:\n",
    "        return False, \"Filename does not match BITS ID inside notebook\", 0\n",
    "\n",
    "    # Student name from notebook (search all cell types)\n",
    "    student_name = None\n",
    "    for cell in nb.cells:\n",
    "        for line in cell.source.split(\"\\n\"):\n",
    "            if line.lower().strip().startswith(\"name\"):\n",
    "                student_name = line.split(\":\", 1)[1].strip()\n",
    "                break\n",
    "        if student_name:\n",
    "            break\n",
    "\n",
    "    if not student_name or folder_name.lower() != student_name.lower():\n",
    "        return False, \"Folder name does not match student name in notebook\", 0\n",
    "\n",
    "    # Execution check\n",
    "    if not any(c.cell_type == \"code\" and c.get(\"outputs\") for c in nb.cells):\n",
    "        return False, \"All outputs cleared - notebook not executed\", 0\n",
    "\n",
    "    # Error check\n",
    "    for cell in nb.cells:\n",
    "        for out in cell.get(\"outputs\", []):\n",
    "            if out.get(\"output_type\") == \"error\":\n",
    "                return False, \"Notebook contains execution errors\", 0\n",
    "\n",
    "    return True, \"Pre-validation successful\", nb\n",
    "\n",
    "# ============================================================\n",
    "# ----------------- CNN_STRICT_GRADING ------------------------\n",
    "# ============================================================\n",
    "\n",
    "def CNN_STRICT_GRADING(nb):\n",
    "    total_marks = 0\n",
    "    breakdown = {}\n",
    "    comments = []\n",
    "\n",
    "    source_code = extract_all_source_code(nb)\n",
    "    json_data = extract_json_output(nb)\n",
    "\n",
    "    if not json_data:\n",
    "        comments.append(\"No JSON output found\")\n",
    "        return 0, breakdown, comments\n",
    "\n",
    "    custom = json_data.get(\"custom_cnn\", {})\n",
    "    tl = json_data.get(\"transfer_learning\", {})\n",
    "    metrics = [\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    "\n",
    "    # ---------- SECTION 1: Custom CNN (5) ----------\n",
    "    score = 0\n",
    "    has_conv = \"Conv2D\" in source_code or \"nn.Conv2d\" in source_code\n",
    "    has_gap = (\n",
    "        \"GlobalAveragePooling\" in source_code\n",
    "        or \"AdaptiveAvgPool\" in source_code\n",
    "        or custom.get(\"architecture\", {}).get(\"has_global_average_pooling\") is True\n",
    "    )\n",
    "    uses_flatten_dense = (\n",
    "        (\"Flatten\" in source_code or \"flatten\" in source_code)\n",
    "        and (\"Dense\" in source_code or \"Linear\" in source_code)\n",
    "        and not has_gap\n",
    "    )\n",
    "\n",
    "    if has_conv and has_gap and not uses_flatten_dense:\n",
    "        score += 2\n",
    "    else:\n",
    "        comments.append(\"Custom CNN architecture incorrect or missing GAP\")\n",
    "\n",
    "    framework = custom.get(\"framework\", \"\").lower()\n",
    "    if framework in [\"keras\", \"tensorflow\"] and \"compile(\" in source_code:\n",
    "        score += 1\n",
    "    elif framework == \"pytorch\" and \"optimizer\" in source_code and \"criterion\" in source_code:\n",
    "        score += 1\n",
    "    else:\n",
    "        comments.append(\"Custom CNN not properly configured\")\n",
    "\n",
    "    if custom.get(\"initial_loss\") and custom.get(\"final_loss\"):\n",
    "        score += 1\n",
    "    else:\n",
    "        comments.append(\"Custom CNN loss values missing\")\n",
    "\n",
    "    if sum(1 for m in metrics if custom.get(m)) == 4:\n",
    "        score += 1\n",
    "    else:\n",
    "        comments.append(\"Custom CNN metrics incomplete\")\n",
    "\n",
    "    breakdown[\"custom_cnn\"] = score\n",
    "    total_marks += score\n",
    "\n",
    "    # ---------- SECTION 2: Transfer Learning (5) ----------\n",
    "    score = 0\n",
    "    base_model = tl.get(\"base_model\", \"\").lower()\n",
    "    valid_models = [\"resnet18\", \"resnet50\", \"vgg16\", \"vgg19\"]\n",
    "\n",
    "    if any(m in base_model for m in valid_models) and tl.get(\"frozen_layers\", 0) > 0:\n",
    "        score += 2\n",
    "    else:\n",
    "        comments.append(\"Transfer learning base model or freezing incorrect\")\n",
    "\n",
    "    if tl.get(\"has_global_average_pooling\") is True:\n",
    "        score += 1\n",
    "    else:\n",
    "        comments.append(\"Transfer learning missing GAP\")\n",
    "\n",
    "    if tl.get(\"initial_loss\") and tl.get(\"final_loss\"):\n",
    "        score += 1\n",
    "    else:\n",
    "        comments.append(\"Transfer learning loss missing\")\n",
    "\n",
    "    if sum(1 for m in metrics if tl.get(m)) == 4:\n",
    "        score += 1\n",
    "    else:\n",
    "        comments.append(\"Transfer learning metrics incomplete\")\n",
    "\n",
    "    breakdown[\"transfer_learning\"] = score\n",
    "    total_marks += score\n",
    "\n",
    "    # ---------- SECTION 3: Loss Convergence (4) ----------\n",
    "    def convergence(init, final):\n",
    "        if init and final and final < init:\n",
    "            pct = ((init - final) / init) * 100\n",
    "            if pct >= 50: return 2\n",
    "            if pct >= 20: return 1\n",
    "        return 0\n",
    "\n",
    "    score = convergence(custom.get(\"initial_loss\"), custom.get(\"final_loss\")) + \\\n",
    "            convergence(tl.get(\"initial_loss\"), tl.get(\"final_loss\"))\n",
    "\n",
    "    breakdown[\"training_process\"] = score\n",
    "    total_marks += score\n",
    "\n",
    "    # ---------- SECTION 4: Metrics Validation (2) ----------\n",
    "    def valid_metrics(data):\n",
    "        return all(0 <= data.get(m, -1) <= 1 for m in metrics)\n",
    "\n",
    "    cnn_ok = valid_metrics(custom)\n",
    "    tl_ok = valid_metrics(tl)\n",
    "\n",
    "    score = 2 if cnn_ok and tl_ok else 1 if cnn_ok or tl_ok else 0\n",
    "    if score == 0:\n",
    "        comments.append(\"Metrics missing or invalid\")\n",
    "\n",
    "    breakdown[\"metrics\"] = score\n",
    "    total_marks += score\n",
    "\n",
    "    # ---------- SECTION 5: Analysis (2) ----------\n",
    "    score = 0\n",
    "    analysis = json_data.get(\"analysis\") or extract_analysis_from_markdown(nb)\n",
    "    if count_words(analysis) > 200:\n",
    "        comments.append(\"Warning: Analysis exceeds 200 words\")\n",
    "\n",
    "    keywords = [\n",
    "        \"performance\", \"accuracy\", \"precision\", \"recall\", \"f1\",\n",
    "        \"transfer\", \"pretrained\", \"gap\", \"overfitting\",\n",
    "        \"convergence\", \"loss\", \"computational\"\n",
    "    ]\n",
    "    covered = sum(1 for k in keywords if k in analysis.lower())\n",
    "    score = 2 if covered >= 8 else 1 if covered >= 5 else 0\n",
    "    if score == 0:\n",
    "        comments.append(\"Analysis lacks depth\")\n",
    "\n",
    "    breakdown[\"analysis\"] = score\n",
    "    total_marks += score\n",
    "\n",
    "    # ---------- SECTION 6: Code Structure (2) ----------\n",
    "    score = 0\n",
    "    if has_conv and (\"ResNet\" in source_code or \"VGG\" in source_code):\n",
    "        score += 1\n",
    "    if \"custom_cnn\" in json_data and \"transfer_learning\" in json_data:\n",
    "        score += 1\n",
    "\n",
    "    breakdown[\"code_structure\"] = score\n",
    "    total_marks += score\n",
    "\n",
    "    return total_marks, breakdown, comments\n",
    "\n",
    "# ============================================================\n",
    "# --------------------- FINAL DRIVER --------------------------\n",
    "# ============================================================\n",
    "\n",
    "def AUTO_GRADE_CNN(notebook_path, folder_name):\n",
    "    ok, msg, result = pre_validate_cnn(notebook_path, folder_name)\n",
    "\n",
    "    if not ok:\n",
    "        return {\n",
    "            \"status\": \"FAIL\",\n",
    "            \"reason\": msg,\n",
    "            \"total_marks\": 0\n",
    "        }\n",
    "\n",
    "    total, breakdown, comments = CNN_STRICT_GRADING(result)\n",
    "\n",
    "    return {\n",
    "        \"status\": \"PASS\",\n",
    "        \"message\": msg,\n",
    "        \"total_marks\": total,\n",
    "        \"breakdown\": breakdown,\n",
    "        \"comments\": comments\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1000600-4521-4298-becd-1f8ac17a22a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'PASS',\n",
       " 'message': 'Pre-validation successful',\n",
       " 'total_marks': 0,\n",
       " 'breakdown': {},\n",
       " 'comments': ['No JSON output found']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grade RNN assignment (run from project root so path is valid)\n",
    "AUTO_GRADE_CNN(\n",
    "    notebook_path=\"2025aa05387_RNN_assignment.ipynb\",\n",
    "    folder_name=\"SHELAR SACHIN KRISHNA\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc544ea-6770-4fe1-a39a-0b5a7a52d12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1146ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
