{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c3561c56",
      "metadata": {
        "id": "c3561c56"
      },
      "source": [
        "# DEEP NEURAL NETWORKS - ASSIGNMENT 2: CNN FOR IMAGE CLASSIFICATION\n",
        "\n",
        "## Convolutional Neural Networks: Custom Implementation vs Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb7be6ad",
      "metadata": {
        "id": "fb7be6ad"
      },
      "source": [
        "STUDENT INFORMATION (REQUIRED - DO NOT DELETE)\n",
        "\n",
        "BITS ID: 2025AA05387\n",
        "\n",
        "Name: SHELAR SACHIN KRISHNA\n",
        "\n",
        "Email: 2025aa05387@wilp.bits-pilani.ac.in\n",
        "\n",
        "Date: 07-FEB-2026"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be209f24",
      "metadata": {
        "id": "be209f24"
      },
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "972a1a99",
      "metadata": {
        "id": "972a1a99"
      },
      "source": [
        "### 1.1 Dataset Selection and Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd47da0",
      "metadata": {
        "id": "ccd47da0"
      },
      "outputs": [],
      "source": [
        "# Load Cats vs Dogs from TensorFlow Datasets (1500 images total)\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "N_SAMPLES = 1500\n",
        "\n",
        "def preprocess(image, label):\n",
        "    \"\"\"Resize and normalize images, one-hot encode labels.\"\"\"\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    image = image / 255.0\n",
        "    label = tf.one_hot(label, depth=2)\n",
        "    return image, label\n",
        "\n",
        "# Load 1500 images (meets 500 per class minimum - dataset is roughly balanced)\n",
        "dataset, info = tfds.load('cats_vs_dogs', split=f'train[:{N_SAMPLES}]', as_supervised=True, with_info=True)\n",
        "\n",
        "# Preprocess and shuffle\n",
        "dataset = dataset.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "dataset = dataset.shuffle(N_SAMPLES, seed=42)\n",
        "\n",
        "# Split 90/10 train/test\n",
        "train_size = int(0.9 * N_SAMPLES)\n",
        "test_size = N_SAMPLES - train_size\n",
        "train_dataset = dataset.take(train_size)\n",
        "test_dataset = dataset.skip(train_size)\n",
        "\n",
        "# Validation: 10% of training for monitoring during fit\n",
        "val_size = int(0.1 * train_size)\n",
        "train_for_fit = train_dataset.skip(val_size).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "val_ds = train_dataset.take(val_size).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "test_ds = test_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# For evaluation: batched test dataset\n",
        "train_samples = train_size - val_size\n",
        "test_samples = test_size\n",
        "\n",
        "print(\"Dataset loaded successfully\")\n",
        "print(f\"Training: {train_samples} samples, Validation: {val_size} samples, Test: {test_samples} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e736527",
      "metadata": {
        "id": "6e736527"
      },
      "outputs": [],
      "source": [
        "# Dataset metadata\n",
        "dataset_name = \"Cats vs Dogs\"\n",
        "dataset_source = \"TensorFlow Datasets (tfds)\"\n",
        "n_samples = N_SAMPLES\n",
        "n_classes = 2\n",
        "samples_per_class = \"750 (balanced, 2 classes)\"\n",
        "image_shape = [IMG_SIZE, IMG_SIZE, 3]\n",
        "problem_type = \"classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a03e43",
      "metadata": {
        "id": "88a03e43"
      },
      "outputs": [],
      "source": [
        "# Primary metric selection\n",
        "primary_metric = \"accuracy\"\n",
        "metric_justification = \"Accuracy is appropriate for this balanced binary classification (cats vs dogs) dataset, where both classes are equally important and we have roughly equal samples per class.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23501291",
      "metadata": {
        "id": "23501291"
      },
      "outputs": [],
      "source": [
        "print(\"DATASET INFORMATION\")\n",
        "print(f\"Dataset: {dataset_name}\")\n",
        "print(f\"Source: {dataset_source}\")\n",
        "print(f\"Total Samples: {n_samples}\")\n",
        "print(f\"Number of Classes: {n_classes}\")\n",
        "print(f\"Samples per Class: {samples_per_class}\")\n",
        "print(f\"Image Shape: {image_shape}\")\n",
        "print(f\"Primary Metric: {primary_metric}\")\n",
        "print(f\"Metric Justification: {metric_justification}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d410ae6",
      "metadata": {
        "id": "1d410ae6"
      },
      "source": [
        "### 1.2 Data Exploration and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94096315",
      "metadata": {
        "id": "94096315"
      },
      "outputs": [],
      "source": [
        "# Sample images and class distribution\n",
        "sample_ds = dataset.take(8).batch(8)\n",
        "for images, labels in sample_ds:\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(images[i].numpy())\n",
        "        ax.set_title(\"Cat\" if labels[i][0] == 1 else \"Dog\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.suptitle(\"Sample Images - Cats vs Dogs\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1059bd58",
      "metadata": {
        "id": "1059bd58"
      },
      "source": [
        "### 1.3 Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ff05ae",
      "metadata": {
        "id": "c9ff05ae"
      },
      "outputs": [],
      "source": [
        "# Document split (train_samples, test_samples set in data loading cell)\n",
        "train_test_ratio = \"90/10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ae8952",
      "metadata": {
        "id": "c3ae8952"
      },
      "outputs": [],
      "source": [
        "print(f\"\\nTrain/Test Split: {train_test_ratio}\")\n",
        "print(f\"Training Samples: {train_samples}\")\n",
        "print(f\"Test Samples: {test_samples}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709a1426",
      "metadata": {
        "id": "709a1426"
      },
      "source": [
        "### 2.1 Custom CNN Architecture Design - KERAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a42b21d7",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "a42b21d7"
      },
      "outputs": [],
      "source": [
        "def build_custom_cnn(input_shape, n_classes):\n",
        "    \"\"\"\n",
        "    Build custom CNN architecture with Global Average Pooling (MANDATORY).\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Input(shape=input_shape),\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.GlobalAveragePooling2D(),  # MANDATORY - no Flatten+Dense\n",
        "        keras.layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "169c3ff6",
      "metadata": {
        "id": "169c3ff6"
      },
      "outputs": [],
      "source": [
        "# Create model instance (already compiled in build_custom_cnn)\n",
        "custom_cnn = build_custom_cnn(image_shape, n_classes)\n",
        "custom_cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e79ff01f",
      "metadata": {
        "id": "e79ff01f"
      },
      "source": [
        "### 2.2 Train Custom CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1017613c",
      "metadata": {
        "id": "1017613c"
      },
      "outputs": [],
      "source": [
        "print(\"\\nCUSTOM CNN TRAINING\")\n",
        "# Track training time\n",
        "custom_cnn_start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e274ecb",
      "metadata": {
        "id": "3e274ecb"
      },
      "outputs": [],
      "source": [
        "# Train custom CNN\n",
        "custom_cnn_epochs = 20\n",
        "custom_cnn_history = custom_cnn.fit(train_for_fit, epochs=custom_cnn_epochs, validation_data=val_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e0db0e",
      "metadata": {
        "id": "42e0db0e"
      },
      "outputs": [],
      "source": [
        "custom_cnn_training_time = time.time() - custom_cnn_start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "748cf308",
      "metadata": {
        "id": "748cf308"
      },
      "outputs": [],
      "source": [
        "# Track initial and final loss from training history\n",
        "custom_cnn_initial_loss = float(custom_cnn_history.history['loss'][0])\n",
        "custom_cnn_final_loss = float(custom_cnn_history.history['loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca325a3",
      "metadata": {
        "id": "fca325a3"
      },
      "outputs": [],
      "source": [
        "print(f\"Training completed in {custom_cnn_training_time:.2f} seconds\")\n",
        "print(f\"Initial Loss: {custom_cnn_initial_loss:.4f}\")\n",
        "print(f\"Final Loss: {custom_cnn_final_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c81ab02",
      "metadata": {
        "id": "7c81ab02"
      },
      "outputs": [],
      "source": [
        "print(\"\\nCUSTOM CNN EVALUATION\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db0090d1",
      "metadata": {
        "id": "db0090d1"
      },
      "source": [
        "### 2.3 Evaluate Custom CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7796b66",
      "metadata": {
        "id": "e7796b66"
      },
      "outputs": [],
      "source": [
        "# Get predictions and compute metrics\n",
        "y_true_custom, y_pred_proba_custom = [], []\n",
        "for images, labels in test_ds:\n",
        "    preds = custom_cnn.predict(images, verbose=0)\n",
        "    y_true_custom.extend(np.argmax(labels.numpy(), axis=1))\n",
        "    y_pred_proba_custom.extend(preds)\n",
        "y_pred_custom = np.argmax(np.array(y_pred_proba_custom), axis=1)\n",
        "y_true_custom = np.array(y_true_custom)\n",
        "\n",
        "custom_cnn_accuracy = float(accuracy_score(y_true_custom, y_pred_custom))\n",
        "custom_cnn_precision = float(precision_score(y_true_custom, y_pred_custom, average='macro', zero_division=0))\n",
        "custom_cnn_recall = float(recall_score(y_true_custom, y_pred_custom, average='macro', zero_division=0))\n",
        "custom_cnn_f1 = float(f1_score(y_true_custom, y_pred_custom, average='macro', zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "701dd335",
      "metadata": {
        "id": "701dd335"
      },
      "outputs": [],
      "source": [
        "print(\"\\nCustom CNN Performance:\")\n",
        "print(f\"Accuracy:  {custom_cnn_accuracy:.4f}\")\n",
        "print(f\"Precision: {custom_cnn_precision:.4f}\")\n",
        "print(f\"Recall:    {custom_cnn_recall:.4f}\")\n",
        "print(f\"F1-Score:  {custom_cnn_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eac1b9f",
      "metadata": {
        "id": "1eac1b9f"
      },
      "source": [
        "### 2.4 Visualize Custom CNN Results\n",
        "- Plot training loss curve\n",
        "- Plot confusion matrix\n",
        "- Show sample predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10d1417",
      "metadata": {
        "id": "a10d1417"
      },
      "outputs": [],
      "source": [
        "# Custom CNN: Training curves and confusion matrix\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].plot(custom_cnn_history.history['loss'], label='Train Loss')\n",
        "axes[0].plot(custom_cnn_history.history['val_loss'], label='Val Loss')\n",
        "axes[0].set_title('Custom CNN - Training Loss')\n",
        "axes[0].legend()\n",
        "axes[0].set_xlabel('Epoch')\n",
        "cm = confusion_matrix(y_true_custom, y_pred_custom)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'], ax=axes[1])\n",
        "axes[1].set_title('Custom CNN - Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f11c6095",
      "metadata": {
        "id": "f11c6095"
      },
      "source": [
        "## 3.1 Load Pre-trained Model and Modify Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b730caa",
      "metadata": {
        "id": "5b730caa"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRANSFER LEARNING IMPLEMENTATION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77826188",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "77826188"
      },
      "outputs": [],
      "source": [
        "# Use ResNet50 pre-trained on ImageNet\n",
        "pretrained_model_name = \"ResNet50\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da80ccd2",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "da80ccd2"
      },
      "outputs": [],
      "source": [
        "def build_transfer_learning_model(base_model_name, input_shape, n_classes):\n",
        "    \"\"\"Build transfer learning model with frozen base and GAP + custom head.\"\"\"\n",
        "    if base_model_name == \"ResNet50\":\n",
        "        base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "        preprocess_fn = keras.applications.resnet50.preprocess_input\n",
        "    elif base_model_name == \"VGG16\":\n",
        "        base_model = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "        preprocess_fn = keras.applications.vgg16.preprocess_input\n",
        "    else:\n",
        "        base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "        preprocess_fn = keras.applications.resnet50.preprocess_input\n",
        "\n",
        "    base_model.trainable = False  # Freeze base layers\n",
        "\n",
        "    # Preprocess: our images are [0,1], ResNet/VGG expect [0,255] for preprocess_input\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Lambda(lambda x: preprocess_fn(x * 255.0), input_shape=input_shape),\n",
        "        base_model,\n",
        "        keras.layers.GlobalAveragePooling2D(),  # MANDATORY\n",
        "        keras.layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbfcd14a",
      "metadata": {
        "id": "bbfcd14a"
      },
      "outputs": [],
      "source": [
        "# Create transfer learning model\n",
        "transfer_model = build_transfer_learning_model(pretrained_model_name, image_shape, n_classes)\n",
        "transfer_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9628ff28",
      "metadata": {
        "id": "9628ff28"
      },
      "outputs": [],
      "source": [
        "# Count layers and parameters (base model is at index 1 after Lambda)\n",
        "base = transfer_model.layers[1]\n",
        "frozen_layers = len(base.layers)\n",
        "trainable_layers = 2  # GAP + Dense in custom head\n",
        "total_parameters = int(transfer_model.count_params())\n",
        "trainable_parameters = int(sum(tf.keras.backend.count_params(w) for w in transfer_model.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16425da9",
      "metadata": {
        "id": "16425da9"
      },
      "outputs": [],
      "source": [
        "print(f\"Base Model: {pretrained_model_name}\")\n",
        "print(f\"Frozen Layers: {frozen_layers}\")\n",
        "print(f\"Trainable Layers: {trainable_layers}\")\n",
        "print(f\"Total Parameters: {total_parameters:,}\")\n",
        "print(f\"Trainable Parameters: {trainable_parameters:,}\")\n",
        "print(f\"Using Global Average Pooling: YES\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6007d532",
      "metadata": {
        "id": "6007d532"
      },
      "source": [
        "### 3.2 Train Transfer Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ae60dc",
      "metadata": {
        "id": "f8ae60dc"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTraining Transfer Learning Model...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e1508f",
      "metadata": {
        "id": "07e1508f"
      },
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "tl_learning_rate = 0.001\n",
        "tl_epochs = 10\n",
        "tl_batch_size = 32\n",
        "tl_optimizer = \"Adam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bfde0a9",
      "metadata": {
        "id": "7bfde0a9"
      },
      "outputs": [],
      "source": [
        "# Track training time\n",
        "tl_start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80090240",
      "metadata": {
        "id": "80090240"
      },
      "outputs": [],
      "source": [
        "# Train transfer learning model\n",
        "tl_history = transfer_model.fit(train_for_fit, epochs=tl_epochs, validation_data=val_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb1df61",
      "metadata": {
        "id": "1fb1df61"
      },
      "outputs": [],
      "source": [
        "tl_training_time = time.time() - tl_start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1d64ec",
      "metadata": {
        "id": "de1d64ec"
      },
      "outputs": [],
      "source": [
        "# Track initial and final loss from training history\n",
        "tl_initial_loss = float(tl_history.history['loss'][0])\n",
        "tl_final_loss = float(tl_history.history['loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00548043",
      "metadata": {
        "id": "00548043"
      },
      "outputs": [],
      "source": [
        "print(f\"Training completed in {tl_training_time:.2f} seconds\")\n",
        "print(f\"Initial Loss: {tl_initial_loss:.4f}\")\n",
        "print(f\"Final Loss: {tl_final_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67a01fcf",
      "metadata": {
        "id": "67a01fcf"
      },
      "source": [
        "### 3.3 Evaluate Transfer Learning Model\n",
        "- Make predictions on test set\n",
        "- Calculate all 4 required metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfbb6ab7",
      "metadata": {
        "id": "dfbb6ab7"
      },
      "outputs": [],
      "source": [
        "# Get predictions and compute metrics for transfer learning\n",
        "y_true_tl, y_pred_proba_tl = [], []\n",
        "for images, labels in test_ds:\n",
        "    preds = transfer_model.predict(images, verbose=0)\n",
        "    y_true_tl.extend(np.argmax(labels.numpy(), axis=1))\n",
        "    y_pred_proba_tl.extend(preds)\n",
        "y_pred_tl = np.argmax(np.array(y_pred_proba_tl), axis=1)\n",
        "y_true_tl = np.array(y_true_tl)\n",
        "\n",
        "tl_accuracy = float(accuracy_score(y_true_tl, y_pred_tl))\n",
        "tl_precision = float(precision_score(y_true_tl, y_pred_tl, average='macro', zero_division=0))\n",
        "tl_recall = float(recall_score(y_true_tl, y_pred_tl, average='macro', zero_division=0))\n",
        "tl_f1 = float(f1_score(y_true_tl, y_pred_tl, average='macro', zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c7266a",
      "metadata": {
        "id": "49c7266a"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTransfer Learning Performance:\")\n",
        "print(f\"Accuracy:  {tl_accuracy:.4f}\")\n",
        "print(f\"Precision: {tl_precision:.4f}\")\n",
        "print(f\"Recall:    {tl_recall:.4f}\")\n",
        "print(f\"F1-Score:  {tl_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "795e7279",
      "metadata": {
        "id": "795e7279"
      },
      "source": [
        "### 3.4 Visualize Transfer Learning Results\n",
        "Implemented below:\n",
        "- **Training curves:** loss and accuracy (train/val) over epochs\n",
        "- **Confusion matrix:** heatmap of predicted vs true labels\n",
        "- **Sample predictions:** grid of test images with Pred vs True (green=correct, red=wrong)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4fbfaf0",
      "metadata": {
        "id": "c4fbfaf0"
      },
      "outputs": [],
      "source": [
        "# Transfer Learning: Training curves (loss + accuracy) and confusion matrix\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "# Loss\n",
        "axes[0].plot(tl_history.history['loss'], label='Train Loss')\n",
        "axes[0].plot(tl_history.history['val_loss'], label='Val Loss')\n",
        "axes[0].set_title('Transfer Learning (ResNet50) - Training Loss')\n",
        "axes[0].legend()\n",
        "axes[0].set_xlabel('Epoch')\n",
        "# Accuracy\n",
        "axes[1].plot(tl_history.history['accuracy'], label='Train Accuracy')\n",
        "axes[1].plot(tl_history.history['val_accuracy'], label='Val Accuracy')\n",
        "axes[1].set_title('Transfer Learning - Training Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].set_xlabel('Epoch')\n",
        "# Confusion matrix\n",
        "cm_tl = confusion_matrix(y_true_tl, y_pred_tl)\n",
        "sns.heatmap(cm_tl, annot=True, fmt='d', cmap='Blues', xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'], ax=axes[2])\n",
        "axes[2].set_title('Transfer Learning - Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdd0e294",
      "metadata": {
        "id": "bdd0e294"
      },
      "outputs": [],
      "source": [
        "# Sample predictions: show test images with predicted vs true labels\n",
        "batch = next(iter(test_ds))\n",
        "images_batch, labels_batch = batch[0], batch[1]\n",
        "preds_batch = transfer_model.predict(images_batch, verbose=0)\n",
        "pred_labels = np.argmax(preds_batch, axis=1)\n",
        "true_labels = np.argmax(labels_batch.numpy(), axis=1)\n",
        "class_names = ['Cat', 'Dog']\n",
        "n_show = min(8, images_batch.shape[0])\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "axes = axes.flat\n",
        "for i in range(n_show):\n",
        "    axes[i].imshow(images_batch[i].numpy())\n",
        "    pred_str = class_names[pred_labels[i]]\n",
        "    true_str = class_names[true_labels[i]]\n",
        "    color = 'green' if pred_labels[i] == true_labels[i] else 'red'\n",
        "    axes[i].set_title(f'Pred: {pred_str}\\nTrue: {true_str}', color=color, fontsize=10)\n",
        "    axes[i].axis('off')\n",
        "for j in range(n_show, len(axes)):\n",
        "    axes[j].axis('off')\n",
        "plt.suptitle('Transfer Learning - Sample Predictions (green=correct, red=wrong)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e9a4ea0",
      "metadata": {
        "id": "8e9a4ea0"
      },
      "source": [
        "## 4.1 Metrics Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e51221e",
      "metadata": {
        "id": "8e51221e"
      },
      "outputs": [],
      "source": [
        "custom_cnn_total_params = int(custom_cnn.count_params())\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time (s)', 'Parameters'],\n",
        "    'Custom CNN': [\n",
        "        custom_cnn_accuracy,\n",
        "        custom_cnn_precision,\n",
        "        custom_cnn_recall,\n",
        "        custom_cnn_f1,\n",
        "        custom_cnn_training_time,\n",
        "        custom_cnn_total_params\n",
        "    ],\n",
        "    'Transfer Learning': [\n",
        "        tl_accuracy,\n",
        "        tl_precision,\n",
        "        tl_recall,\n",
        "        tl_f1,\n",
        "        tl_training_time,\n",
        "        trainable_parameters\n",
        "    ]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d56dde6",
      "metadata": {
        "id": "5d56dde6"
      },
      "outputs": [],
      "source": [
        "print(comparison_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78d54a9d",
      "metadata": {
        "id": "78d54a9d"
      },
      "outputs": [],
      "source": [
        "# Bar plot comparing metrics\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "ax.bar(x - width/2, [custom_cnn_accuracy, custom_cnn_precision, custom_cnn_recall, custom_cnn_f1], width, label='Custom CNN')\n",
        "ax.bar(x + width/2, [tl_accuracy, tl_precision, tl_recall, tl_f1], width, label='Transfer Learning')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Model Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffd6002a",
      "metadata": {
        "id": "ffd6002a"
      },
      "source": [
        "### 4.2 Visual Comparison\n",
        "- Create bar plot comparing metrics\n",
        "- Plot training curves comparison\n",
        "- Create side-by-side confusion matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "638f373a",
      "metadata": {
        "id": "638f373a"
      },
      "outputs": [],
      "source": [
        "analysis_text = \"\"\"\n",
        "Performance: The transfer learning model (ResNet50) typically outperforms the custom CNN in accuracy, precision, recall, and F1-score due to pre-trained ImageNet features. The custom CNN trains from scratch and may achieve lower metrics but demonstrates the value of learning domain-specific features.\n",
        "\n",
        "Pre-training vs from scratch: Transfer learning converges faster and achieves better results because the base model already learned rich visual features (edges, textures, object parts) on millions of images. The custom CNN must learn these from limited data.\n",
        "\n",
        "Global Average Pooling: GAP reduces overfitting by dramatically decreasing parameters compared to Flatten+Dense. It outputs one value per feature map, forcing spatial invariance and regularization.\n",
        "\n",
        "Computational cost: The transfer learning model has far more total parameters (ResNet50 base) but fewer trainable parameters (only the classification head). Training time may be similar or longer for transfer learning due to forward passes through the deep base. The custom CNN has fewer parameters overall and trains faster per epoch.\n",
        "\n",
        "Transfer learning insights: Transfer learning excels when training data is limited. The custom CNN is suitable when data is abundant or the domain differs significantly from ImageNet. Both models benefit from GAP for regularization.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "391f4b03",
      "metadata": {
        "id": "391f4b03"
      },
      "outputs": [],
      "source": [
        "# REQUIRED: Print analysis with word count\n",
        "print(\"ANALYSIS\")\n",
        "print(analysis_text)\n",
        "print(f\"Analysis word count: {len(analysis_text.split())} words\")\n",
        "if len(analysis_text.split()) > 200:\n",
        "    print(\"  Warning: Analysis exceeds 200 words (guideline)\")\n",
        "else:\n",
        "    print(\" Analysis within word count guideline\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7580f5ac",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "7580f5ac"
      },
      "outputs": [],
      "source": [
        "def get_assignment_results():\n",
        "    \"\"\"\n",
        "    Generate complete assignment results in required format\n",
        "\n",
        "    Returns:\n",
        "        dict: Complete results with all required fields\n",
        "    \"\"\"\n",
        "\n",
        "    framework_used = \"keras\"\n",
        "\n",
        "    results = {\n",
        "        # Dataset Information\n",
        "        'dataset_name': dataset_name,\n",
        "        'dataset_source': dataset_source,\n",
        "        'n_samples': n_samples,\n",
        "        'n_classes': n_classes,\n",
        "        'samples_per_class': samples_per_class,\n",
        "        'image_shape': image_shape,\n",
        "        'problem_type': problem_type,\n",
        "        'primary_metric': primary_metric,\n",
        "        'metric_justification': metric_justification,\n",
        "        'train_samples': train_samples,\n",
        "        'test_samples': test_samples,\n",
        "        'train_test_ratio': train_test_ratio,\n",
        "\n",
        "        # Custom CNN Results\n",
        "        'custom_cnn': {\n",
        "            'framework': framework_used,\n",
        "            'architecture': {\n",
        "                'conv_layers': 3,\n",
        "                'pooling_layers': 3,\n",
        "                'has_global_average_pooling': True,\n",
        "                'output_layer': 'softmax',\n",
        "                'total_parameters': custom_cnn_total_params\n",
        "            },\n",
        "            'training_config': {\n",
        "                'learning_rate': 0.001,\n",
        "                'n_epochs': custom_cnn_epochs,\n",
        "                'batch_size': BATCH_SIZE,\n",
        "                'optimizer': 'Adam',\n",
        "                'loss_function': 'categorical_crossentropy'\n",
        "            },\n",
        "            'initial_loss': custom_cnn_initial_loss,\n",
        "            'final_loss': custom_cnn_final_loss,\n",
        "            'training_time_seconds': custom_cnn_training_time,\n",
        "            'accuracy': custom_cnn_accuracy,\n",
        "            'precision': custom_cnn_precision,\n",
        "            'recall': custom_cnn_recall,\n",
        "            'f1_score': custom_cnn_f1\n",
        "        },\n",
        "\n",
        "        # Transfer Learning Results\n",
        "        'transfer_learning': {\n",
        "            'framework': framework_used,\n",
        "            'base_model': pretrained_model_name,\n",
        "            'frozen_layers': frozen_layers,\n",
        "            'trainable_layers': trainable_layers,\n",
        "            'has_global_average_pooling': True,  # MUST be True\n",
        "            'total_parameters': total_parameters,\n",
        "            'trainable_parameters': trainable_parameters,\n",
        "            'training_config': {\n",
        "                'learning_rate': tl_learning_rate,\n",
        "                'n_epochs': tl_epochs,\n",
        "                'batch_size': tl_batch_size,\n",
        "                'optimizer': tl_optimizer,\n",
        "                'loss_function': 'categorical_crossentropy'\n",
        "            },\n",
        "            'initial_loss': tl_initial_loss,\n",
        "            'final_loss': tl_final_loss,\n",
        "            'training_time_seconds': tl_training_time,\n",
        "            'accuracy': tl_accuracy,\n",
        "            'precision': tl_precision,\n",
        "            'recall': tl_recall,\n",
        "            'f1_score': tl_f1\n",
        "        },\n",
        "\n",
        "        # Analysis\n",
        "        'analysis': analysis_text,\n",
        "        'analysis_word_count': len(analysis_text.split()),\n",
        "\n",
        "        # Training Success Indicators\n",
        "        'custom_cnn_loss_decreased': custom_cnn_final_loss < custom_cnn_initial_loss if custom_cnn_initial_loss and custom_cnn_final_loss else False,\n",
        "        'transfer_learning_loss_decreased': tl_final_loss < tl_initial_loss if tl_initial_loss and tl_final_loss else False,\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94cec80",
      "metadata": {
        "id": "a94cec80"
      },
      "outputs": [],
      "source": [
        "# Generate and print results\n",
        "try:\n",
        "    assignment_results = get_assignment_results()\n",
        "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
        "    print(json.dumps(assignment_results, indent=2))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n  ERROR generating results: {str(e)}\")\n",
        "    print(\"Please ensure all variables are properly defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4747e6",
      "metadata": {
        "id": "5a4747e6"
      },
      "outputs": [],
      "source": [
        "# Display system information\n",
        "import platform\n",
        "import sys\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5ae62c",
      "metadata": {
        "id": "6e5ae62c"
      },
      "outputs": [],
      "source": [
        "print(\"ENVIRONMENT INFORMATION\")\n",
        "print(\"\\n  REQUIRED: Add screenshot of your Google Colab/BITS Virtual Lab\")\n",
        "print(\"showing your account details in the cell below this one.\")\n",
        "\n",
        "# include the screen shot here"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}