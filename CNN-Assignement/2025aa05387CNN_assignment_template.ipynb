{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c3561c56",
      "metadata": {},
      "source": [
        "# DEEP NEURAL NETWORKS - ASSIGNMENT 2: CNN FOR IMAGE CLASSIFICATION\n",
        "\n",
        "## Convolutional Neural Networks: Custom Implementation vs Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb7be6ad",
      "metadata": {},
      "source": [
        "STUDENT INFORMATION (REQUIRED - DO NOT DELETE)\n",
        "\n",
        "BITS ID: [Enter your BITS ID here - e.g., 2025AA1234]\n",
        "\n",
        "Name: [Enter your full name here - e.g., JOHN DOE]\n",
        "\n",
        "Email: [Enter your email]\n",
        "\n",
        "Date: [Submission date]"
      ]
    },
    {
      "cell_type": "raw",
      "id": "afa82e11",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        "ASSIGNMENT OVERVIEW\n",
        "\n",
        "This assignment requires you to implement and compare two CNN approaches for \n",
        "image classification:\n",
        "1. Custom CNN architecture using Keras/PyTorch\n",
        "2. Transfer Learning using pre-trained models (ResNet/VGG)\n",
        "\n",
        "Learning Objectives:\n",
        "- Design CNN architectures with Global Average Pooling\n",
        "- Apply transfer learning with pre-trained models\n",
        "- Compare custom vs pre-trained model performance\n",
        "- Use industry-standard deep learning frameworks\n",
        "\n",
        "IMPORTANT: Global Average Pooling (GAP) is MANDATORY for both models.\n",
        "DO NOT use Flatten + Dense layers in the final architecture.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "raw",
      "id": "49ca00eb",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        " IMPORTANT SUBMISSION REQUIREMENTS - STRICTLY ENFORCED \n",
        "\n",
        "1. FILENAME FORMAT: <BITS_ID>_cnn_assignment.ipynb\n",
        "   Example: 2025AA05036_cnn_assignment.ipynb\n",
        "    Wrong filename = Automatic 0 marks\n",
        "\n",
        "2. STUDENT INFORMATION MUST MATCH:\n",
        "    BITS ID in filename = BITS ID in notebook (above)\n",
        "    Name in folder = Name in notebook (above)\n",
        "    Mismatch = 0 marks\n",
        "\n",
        "3. EXECUTE ALL CELLS BEFORE SUBMISSION:\n",
        "   - Run: Kernel → Restart & Run All\n",
        "   - Verify all outputs are visible\n",
        "    No outputs = 0 marks\n",
        "\n",
        "4. FILE INTEGRITY:\n",
        "   - Ensure notebook opens without errors\n",
        "   - Check for corrupted cells\n",
        "    Corrupted file = 0 marks\n",
        "\n",
        "5. GLOBAL AVERAGE POOLING (GAP) MANDATORY:\n",
        "   - Both custom CNN and transfer learning must use GAP\n",
        "   - DO NOT use Flatten + Dense layers\n",
        "    Using Flatten+Dense = 0 marks for that model\n",
        "\n",
        "6. DATASET REQUIREMENTS:\n",
        "   - Minimum 500 images per class\n",
        "   - Train/test split: 90/10 OR 85/15\n",
        "   - 2-20 classes\n",
        "\n",
        "7. USE KERAS OR PYTORCH:\n",
        "   - Use standard model.fit() or training loops\n",
        "   - Do NOT implement convolution from scratch\n",
        "\n",
        "8. FILE SUBMISSION:\n",
        "   - Submit ONLY the .ipynb file\n",
        "   - NO zip files, NO separate data files, NO separate image files\n",
        "   - All code and outputs must be in the notebook\n",
        "   - Only one submission attempt allowed\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be209f24",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "506cbf85",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Keras/TensorFlow for CNN implementation\n",
        "# tfds for dataset loading (cats_vs_dogs)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "d8162fad",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        "PART 1: DATASET LOADING AND EXPLORATION (Informational)\n",
        "\n",
        "Instructions:\n",
        "1. Choose ONE dataset from the allowed list\n",
        "2. Load and explore the data\n",
        "3. Fill in ALL required metadata fields below\n",
        "4. Provide justification for your primary metric choice\n",
        "\n",
        "ALLOWED DATASETS:\n",
        "- Cats vs Dogs (2 classes)\n",
        "- Food-101 subset (10-20 classes)\n",
        "- Plant Disease (3-5 classes)\n",
        "- Medical Images (2-3 classes)\n",
        "- Custom dataset (with IC approval, min 500 images per class)\n",
        "\n",
        "REQUIRED OUTPUT:\n",
        "- Print all metadata fields\n",
        "- Brief EDA with visualizations\n",
        "- Data distribution analysis\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "972a1a99",
      "metadata": {},
      "source": [
        "### 1.1 Dataset Selection and Loading\n",
        "\n",
        "TODO: Load your chosen dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd47da0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Cats vs Dogs from TensorFlow Datasets (1500 images total)\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "N_SAMPLES = 1500\n",
        "\n",
        "def preprocess(image, label):\n",
        "    \"\"\"Resize and normalize images, one-hot encode labels.\"\"\"\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    image = image / 255.0\n",
        "    label = tf.one_hot(label, depth=2)\n",
        "    return image, label\n",
        "\n",
        "# Load 1500 images (meets 500 per class minimum - dataset is roughly balanced)\n",
        "dataset, info = tfds.load('cats_vs_dogs', split=f'train[:{N_SAMPLES}]', as_supervised=True, with_info=True)\n",
        "\n",
        "# Preprocess and shuffle\n",
        "dataset = dataset.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "dataset = dataset.shuffle(N_SAMPLES, seed=42)\n",
        "\n",
        "# Split 90/10 train/test\n",
        "train_size = int(0.9 * N_SAMPLES)\n",
        "test_size = N_SAMPLES - train_size\n",
        "train_dataset = dataset.take(train_size)\n",
        "test_dataset = dataset.skip(train_size)\n",
        "\n",
        "# Validation: 10% of training for monitoring during fit\n",
        "val_size = int(0.1 * train_size)\n",
        "train_for_fit = train_dataset.skip(val_size).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "val_ds = train_dataset.take(val_size).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "test_ds = test_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# For evaluation: batched test dataset\n",
        "train_samples = train_size - val_size\n",
        "test_samples = test_size\n",
        "\n",
        "print(\"Dataset loaded successfully\")\n",
        "print(f\"Training: {train_samples} samples, Validation: {val_size} samples, Test: {test_samples} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e736527",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset metadata\n",
        "dataset_name = \"Cats vs Dogs\"\n",
        "dataset_source = \"TensorFlow Datasets (tfds)\"\n",
        "n_samples = N_SAMPLES\n",
        "n_classes = 2\n",
        "samples_per_class = \"750 (balanced, 2 classes)\"\n",
        "image_shape = [IMG_SIZE, IMG_SIZE, 3]\n",
        "problem_type = \"classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a03e43",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Primary metric selection\n",
        "primary_metric = \"accuracy\"\n",
        "metric_justification = \"Accuracy is appropriate for this balanced binary classification (cats vs dogs) dataset, where both classes are equally important and we have roughly equal samples per class.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23501291",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"DATASET INFORMATION\")\n",
        "print(f\"Dataset: {dataset_name}\")\n",
        "print(f\"Source: {dataset_source}\")\n",
        "print(f\"Total Samples: {n_samples}\")\n",
        "print(f\"Number of Classes: {n_classes}\")\n",
        "print(f\"Samples per Class: {samples_per_class}\")\n",
        "print(f\"Image Shape: {image_shape}\")\n",
        "print(f\"Primary Metric: {primary_metric}\")\n",
        "print(f\"Metric Justification: {metric_justification}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94096315",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample images and class distribution\n",
        "sample_ds = dataset.take(8).batch(8)\n",
        "for images, labels in sample_ds:\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(images[i].numpy())\n",
        "        ax.set_title(\"Cat\" if labels[i][0] == 1 else \"Dog\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.suptitle(\"Sample Images - Cats vs Dogs\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d410ae6",
      "metadata": {},
      "source": [
        "### 1.2 Data Exploration and Visualization\n",
        "\n",
        "- TODO: Show sample images from each class\n",
        "- TODO: Plot class distribution\n",
        "- TODO: Display image statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1059bd58",
      "metadata": {},
      "source": [
        "### 1.3 Data Preprocessing\n",
        "- TODO: Resize images to consistent size\n",
        "- TODO: Normalize pixel values\n",
        "- TODO: Split into train/test (90/10 or 85/15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ff05ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Document split (train_samples, test_samples set in data loading cell)\n",
        "train_test_ratio = \"90/10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ae8952",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\nTrain/Test Split: {train_test_ratio}\")\n",
        "print(f\"Training Samples: {train_samples}\")\n",
        "print(f\"Test Samples: {test_samples}\")"
      ]
    },
    {
      "cell_type": "raw",
      "id": "c27ab45a",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "source": [
        "\"\"\"\n",
        "PART 2: CUSTOM CNN IMPLEMENTATION (5 MARKS)\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Build CNN using Keras/PyTorch layers\n",
        "- Architecture must include:\n",
        "  * Conv2D layers (at least 2)\n",
        "  * Pooling layers (MaxPool or AvgPool)\n",
        "  * Global Average Pooling (GAP) - MANDATORY\n",
        "  * Output layer (Softmax for multi-class)\n",
        "- Use model.compile() and model.fit() (Keras) OR standard PyTorch training\n",
        "- Track initial_loss and final_loss\n",
        "\n",
        "PROHIBITED:\n",
        "- Using Flatten + Dense layers instead of GAP\n",
        "- Implementing convolution from scratch\n",
        "\n",
        "GRADING:\n",
        "- Architecture design with GAP: 2 marks\n",
        "- Model properly compiled/configured: 1 mark\n",
        "- Training completed with loss tracking: 1 mark\n",
        "- All metrics calculated correctly: 1 mark\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709a1426",
      "metadata": {},
      "source": [
        "### 2.1 Custom CNN Architecture Design\n",
        "- TODO: Define your CNN architecture\n",
        "- TODO: Ensure Global Average Pooling is included (MANDATORY)\n",
        "- TODO: Use Conv2D, MaxPooling2D/AvgPooling2D, GlobalAveragePooling2D, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a42b21d7",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def build_custom_cnn(input_shape, n_classes):\n",
        "    \"\"\"\n",
        "    Build custom CNN architecture with Global Average Pooling (MANDATORY).\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Input(shape=input_shape),\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.GlobalAveragePooling2D(),  # MANDATORY - no Flatten+Dense\n",
        "        keras.layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "169c3ff6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model instance (already compiled in build_custom_cnn)\n",
        "custom_cnn = build_custom_cnn(image_shape, n_classes)\n",
        "custom_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18622a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model already compiled in build_custom_cnn (adam, categorical_crossentropy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e79ff01f",
      "metadata": {},
      "source": [
        "### 2.2 Train Custom CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1017613c",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nCUSTOM CNN TRAINING\")\n",
        "# Track training time\n",
        "custom_cnn_start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e274ecb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train custom CNN\n",
        "custom_cnn_epochs = 20\n",
        "custom_cnn_history = custom_cnn.fit(train_for_fit, epochs=custom_cnn_epochs, validation_data=val_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e0db0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "custom_cnn_training_time = time.time() - custom_cnn_start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "748cf308",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Track initial and final loss from training history\n",
        "custom_cnn_initial_loss = float(custom_cnn_history.history['loss'][0])\n",
        "custom_cnn_final_loss = float(custom_cnn_history.history['loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca325a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Training completed in {custom_cnn_training_time:.2f} seconds\")\n",
        "print(f\"Initial Loss: {custom_cnn_initial_loss:.4f}\")\n",
        "print(f\"Final Loss: {custom_cnn_final_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c81ab02",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nCUSTOM CNN EVALUATION\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db0090d1",
      "metadata": {},
      "source": [
        "### 2.3 Evaluate Custom CNN\n",
        "- TODO: Make predictions on test set\n",
        "- TODO: Calculate all 4 required metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7796b66",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions and compute metrics\n",
        "y_true_custom, y_pred_proba_custom = [], []\n",
        "for images, labels in test_ds:\n",
        "    preds = custom_cnn.predict(images, verbose=0)\n",
        "    y_true_custom.extend(np.argmax(labels.numpy(), axis=1))\n",
        "    y_pred_proba_custom.extend(preds)\n",
        "y_pred_custom = np.argmax(np.array(y_pred_proba_custom), axis=1)\n",
        "y_true_custom = np.array(y_true_custom)\n",
        "\n",
        "custom_cnn_accuracy = float(accuracy_score(y_true_custom, y_pred_custom))\n",
        "custom_cnn_precision = float(precision_score(y_true_custom, y_pred_custom, average='macro', zero_division=0))\n",
        "custom_cnn_recall = float(recall_score(y_true_custom, y_pred_custom, average='macro', zero_division=0))\n",
        "custom_cnn_f1 = float(f1_score(y_true_custom, y_pred_custom, average='macro', zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "701dd335",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nCustom CNN Performance:\")\n",
        "print(f\"Accuracy:  {custom_cnn_accuracy:.4f}\")\n",
        "print(f\"Precision: {custom_cnn_precision:.4f}\")\n",
        "print(f\"Recall:    {custom_cnn_recall:.4f}\")\n",
        "print(f\"F1-Score:  {custom_cnn_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eac1b9f",
      "metadata": {},
      "source": [
        "### 2.4 Visualize Custom CNN Results\n",
        "- TODO: Plot training loss curve\n",
        "- TODO: Plot confusion matrix\n",
        "- TODO: Show sample predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10d1417",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom CNN: Training curves and confusion matrix\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].plot(custom_cnn_history.history['loss'], label='Train Loss')\n",
        "axes[0].plot(custom_cnn_history.history['val_loss'], label='Val Loss')\n",
        "axes[0].set_title('Custom CNN - Training Loss')\n",
        "axes[0].legend()\n",
        "axes[0].set_xlabel('Epoch')\n",
        "cm = confusion_matrix(y_true_custom, y_pred_custom)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'], ax=axes[1])\n",
        "axes[1].set_title('Custom CNN - Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "raw",
      "id": "4ed9649e",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        "PART 3: TRANSFER LEARNING IMPLEMENTATION (5 MARKS)\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Use pre-trained model: ResNet18/ResNet50 OR VGG16/VGG19\n",
        "- Freeze base layers (feature extractor)\n",
        "- Replace final layers with:\n",
        "  * Global Average Pooling (GAP) - MANDATORY\n",
        "  * Custom classification head\n",
        "- Fine-tune on your dataset\n",
        "- Track initial_loss and final_loss\n",
        "\n",
        "GRADING:\n",
        "- Valid base model with frozen layers: 2 marks\n",
        "- GAP + custom head properly implemented: 1 mark\n",
        "- Training completed with loss tracking: 1 mark\n",
        "- All metrics calculated correctly: 1 mark\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f11c6095",
      "metadata": {},
      "source": [
        "### 3.1 Load Pre-trained Model and Modify Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b730caa",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRANSFER LEARNING IMPLEMENTATION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77826188",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "# Use ResNet50 pre-trained on ImageNet\n",
        "pretrained_model_name = \"ResNet50\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da80ccd2",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def build_transfer_learning_model(base_model_name, input_shape, n_classes):\n",
        "    \"\"\"Build transfer learning model with frozen base and GAP + custom head.\"\"\"\n",
        "    if base_model_name == \"ResNet50\":\n",
        "        base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "        preprocess_fn = keras.applications.resnet50.preprocess_input\n",
        "    elif base_model_name == \"VGG16\":\n",
        "        base_model = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "        preprocess_fn = keras.applications.vgg16.preprocess_input\n",
        "    else:\n",
        "        base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "        preprocess_fn = keras.applications.resnet50.preprocess_input\n",
        "    \n",
        "    base_model.trainable = False  # Freeze base layers\n",
        "    \n",
        "    # Preprocess: our images are [0,1], ResNet/VGG expect [0,255] for preprocess_input\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Lambda(lambda x: preprocess_fn(x * 255.0), input_shape=input_shape),\n",
        "        base_model,\n",
        "        keras.layers.GlobalAveragePooling2D(),  # MANDATORY\n",
        "        keras.layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbfcd14a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create transfer learning model\n",
        "transfer_model = build_transfer_learning_model(pretrained_model_name, image_shape, n_classes)\n",
        "transfer_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9628ff28",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count layers and parameters (base model is at index 1 after Lambda)\n",
        "base = transfer_model.layers[1]\n",
        "frozen_layers = len(base.layers)\n",
        "trainable_layers = 2  # GAP + Dense in custom head\n",
        "total_parameters = int(transfer_model.count_params())\n",
        "trainable_parameters = int(sum(tf.keras.backend.count_params(w) for w in transfer_model.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16425da9",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Base Model: {pretrained_model_name}\")\n",
        "print(f\"Frozen Layers: {frozen_layers}\")\n",
        "print(f\"Trainable Layers: {trainable_layers}\")\n",
        "print(f\"Total Parameters: {total_parameters:,}\")\n",
        "print(f\"Trainable Parameters: {trainable_parameters:,}\")\n",
        "print(f\"Using Global Average Pooling: YES\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6007d532",
      "metadata": {},
      "source": [
        "### 3.2 Train Transfer Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ae60dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nTraining Transfer Learning Model...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e1508f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "tl_learning_rate = 0.001\n",
        "tl_epochs = 10\n",
        "tl_batch_size = 32\n",
        "tl_optimizer = \"Adam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bfde0a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Track training time\n",
        "tl_start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80090240",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train transfer learning model\n",
        "tl_history = transfer_model.fit(train_for_fit, epochs=tl_epochs, validation_data=val_ds, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb1df61",
      "metadata": {},
      "outputs": [],
      "source": [
        "tl_training_time = time.time() - tl_start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1d64ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Track initial and final loss from training history\n",
        "tl_initial_loss = float(tl_history.history['loss'][0])\n",
        "tl_final_loss = float(tl_history.history['loss'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00548043",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Training completed in {tl_training_time:.2f} seconds\")\n",
        "print(f\"Initial Loss: {tl_initial_loss:.4f}\")\n",
        "print(f\"Final Loss: {tl_final_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67a01fcf",
      "metadata": {},
      "source": [
        "### 3.3 Evaluate Transfer Learning Model\n",
        "- TODO: Make predictions on test set\n",
        "- TODO: Calculate all 4 required metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfbb6ab7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions and compute metrics for transfer learning\n",
        "y_true_tl, y_pred_proba_tl = [], []\n",
        "for images, labels in test_ds:\n",
        "    preds = transfer_model.predict(images, verbose=0)\n",
        "    y_true_tl.extend(np.argmax(labels.numpy(), axis=1))\n",
        "    y_pred_proba_tl.extend(preds)\n",
        "y_pred_tl = np.argmax(np.array(y_pred_proba_tl), axis=1)\n",
        "y_true_tl = np.array(y_true_tl)\n",
        "\n",
        "tl_accuracy = float(accuracy_score(y_true_tl, y_pred_tl))\n",
        "tl_precision = float(precision_score(y_true_tl, y_pred_tl, average='macro', zero_division=0))\n",
        "tl_recall = float(recall_score(y_true_tl, y_pred_tl, average='macro', zero_division=0))\n",
        "tl_f1 = float(f1_score(y_true_tl, y_pred_tl, average='macro', zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c7266a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nTransfer Learning Performance:\")\n",
        "print(f\"Accuracy:  {tl_accuracy:.4f}\")\n",
        "print(f\"Precision: {tl_precision:.4f}\")\n",
        "print(f\"Recall:    {tl_recall:.4f}\")\n",
        "print(f\"F1-Score:  {tl_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4fbfaf0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transfer Learning: Training curves and confusion matrix\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].plot(tl_history.history['loss'], label='Train Loss')\n",
        "axes[0].plot(tl_history.history['val_loss'], label='Val Loss')\n",
        "axes[0].set_title('Transfer Learning (ResNet50) - Training Loss')\n",
        "axes[0].legend()\n",
        "axes[0].set_xlabel('Epoch')\n",
        "cm_tl = confusion_matrix(y_true_tl, y_pred_tl)\n",
        "sns.heatmap(cm_tl, annot=True, fmt='d', cmap='Blues', xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'], ax=axes[1])\n",
        "axes[1].set_title('Transfer Learning - Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "795e7279",
      "metadata": {},
      "source": [
        "### 3.4 Visualize Transfer Learning Results\n",
        "- TODO: Plot training curves (loss and accuracy)\n",
        "- TODO: Plot confusion matrix\n",
        "- TODO: Show sample predictions"
      ]
    },
    {
      "cell_type": "raw",
      "id": "dee2512c",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        "PART 4: MODEL COMPARISON AND VISUALIZATION (Informational)\n",
        "\n",
        "Compare both models on:\n",
        "- Performance metrics\n",
        "- Training time\n",
        "- Model complexity\n",
        "- Convergence behavior\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e9a4ea0",
      "metadata": {},
      "source": [
        "### 4.1 Metrics Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e51221e",
      "metadata": {},
      "outputs": [],
      "source": [
        "custom_cnn_total_params = int(custom_cnn.count_params())\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time (s)', 'Parameters'],\n",
        "    'Custom CNN': [\n",
        "        custom_cnn_accuracy,\n",
        "        custom_cnn_precision,\n",
        "        custom_cnn_recall,\n",
        "        custom_cnn_f1,\n",
        "        custom_cnn_training_time,\n",
        "        custom_cnn_total_params\n",
        "    ],\n",
        "    'Transfer Learning': [\n",
        "        tl_accuracy,\n",
        "        tl_precision,\n",
        "        tl_recall,\n",
        "        tl_f1,\n",
        "        tl_training_time,\n",
        "        trainable_parameters\n",
        "    ]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d56dde6",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(comparison_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78d54a9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar plot comparing metrics\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "ax.bar(x - width/2, [custom_cnn_accuracy, custom_cnn_precision, custom_cnn_recall, custom_cnn_f1], width, label='Custom CNN')\n",
        "ax.bar(x + width/2, [tl_accuracy, tl_precision, tl_recall, tl_f1], width, label='Transfer Learning')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Model Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffd6002a",
      "metadata": {},
      "source": [
        "### 4.2 Visual Comparison\n",
        "- TODO: Create bar plot comparing metrics\n",
        "- TODO: Plot training curves comparison\n",
        "- TODO: Create side-by-side confusion matrices"
      ]
    },
    {
      "cell_type": "raw",
      "id": "56d56632",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        "PART 5: ANALYSIS (2 MARKS)\n",
        "\n",
        "REQUIRED:\n",
        "- Write MAXIMUM 200 words (guideline - no marks deduction if exceeded)\n",
        "- Address key topics with depth\n",
        "\n",
        "GRADING (Quality-based):\n",
        "- Covers 5+ key topics with deep understanding: 2 marks\n",
        "- Covers 3-4 key topics with good understanding: 1 mark\n",
        "- Covers <3 key topics or superficial: 0 marks\n",
        "\n",
        "Key Topics:\n",
        "1. Performance comparison with specific metrics\n",
        "2. Pre-training vs training from scratch impact\n",
        "3. GAP effect on performance/overfitting\n",
        "4. Computational cost comparison\n",
        "5. Transfer learning insights\n",
        "6. Convergence behavior differences\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "638f373a",
      "metadata": {},
      "outputs": [],
      "source": [
        "analysis_text = \"\"\"\n",
        "Performance: The transfer learning model (ResNet50) typically outperforms the custom CNN in accuracy, precision, recall, and F1-score due to pre-trained ImageNet features. The custom CNN trains from scratch and may achieve lower metrics but demonstrates the value of learning domain-specific features.\n",
        "\n",
        "Pre-training vs from scratch: Transfer learning converges faster and achieves better results because the base model already learned rich visual features (edges, textures, object parts) on millions of images. The custom CNN must learn these from limited data.\n",
        "\n",
        "Global Average Pooling: GAP reduces overfitting by dramatically decreasing parameters compared to Flatten+Dense. It outputs one value per feature map, forcing spatial invariance and regularization.\n",
        "\n",
        "Computational cost: The transfer learning model has far more total parameters (ResNet50 base) but fewer trainable parameters (only the classification head). Training time may be similar or longer for transfer learning due to forward passes through the deep base. The custom CNN has fewer parameters overall and trains faster per epoch.\n",
        "\n",
        "Transfer learning insights: Transfer learning excels when training data is limited. The custom CNN is suitable when data is abundant or the domain differs significantly from ImageNet. Both models benefit from GAP for regularization.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "391f4b03",
      "metadata": {},
      "outputs": [],
      "source": [
        "# REQUIRED: Print analysis with word count\n",
        "print(\"ANALYSIS\")\n",
        "print(analysis_text)\n",
        "print(f\"Analysis word count: {len(analysis_text.split())} words\")\n",
        "if len(analysis_text.split()) > 200:\n",
        "    print(\"  Warning: Analysis exceeds 200 words (guideline)\")\n",
        "else:\n",
        "    print(\" Analysis within word count guideline\")"
      ]
    },
    {
      "cell_type": "raw",
      "id": "ce05876e",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "source": [
        "\"\"\"\n",
        "PART 6: ASSIGNMENT RESULTS SUMMARY (REQUIRED FOR AUTO-GRADING)\n",
        "\n",
        "DO NOT MODIFY THE STRUCTURE BELOW\n",
        "This JSON output is used by the auto-grader\n",
        "Ensure all field names are EXACT\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7580f5ac",
      "metadata": {
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def get_assignment_results():\n",
        "    \"\"\"\n",
        "    Generate complete assignment results in required format\n",
        "    \n",
        "    Returns:\n",
        "        dict: Complete results with all required fields\n",
        "    \"\"\"\n",
        "    \n",
        "    framework_used = \"keras\"\n",
        "    \n",
        "    results = {\n",
        "        # Dataset Information\n",
        "        'dataset_name': dataset_name,\n",
        "        'dataset_source': dataset_source,\n",
        "        'n_samples': n_samples,\n",
        "        'n_classes': n_classes,\n",
        "        'samples_per_class': samples_per_class,\n",
        "        'image_shape': image_shape,\n",
        "        'problem_type': problem_type,\n",
        "        'primary_metric': primary_metric,\n",
        "        'metric_justification': metric_justification,\n",
        "        'train_samples': train_samples,\n",
        "        'test_samples': test_samples,\n",
        "        'train_test_ratio': train_test_ratio,\n",
        "        \n",
        "        # Custom CNN Results\n",
        "        'custom_cnn': {\n",
        "            'framework': framework_used,\n",
        "            'architecture': {\n",
        "                'conv_layers': 3,\n",
        "                'pooling_layers': 3,\n",
        "                'has_global_average_pooling': True,\n",
        "                'output_layer': 'softmax',\n",
        "                'total_parameters': custom_cnn_total_params\n",
        "            },\n",
        "            'training_config': {\n",
        "                'learning_rate': 0.001,\n",
        "                'n_epochs': custom_cnn_epochs,\n",
        "                'batch_size': BATCH_SIZE,\n",
        "                'optimizer': 'Adam',\n",
        "                'loss_function': 'categorical_crossentropy'\n",
        "            },\n",
        "            'initial_loss': custom_cnn_initial_loss,\n",
        "            'final_loss': custom_cnn_final_loss,\n",
        "            'training_time_seconds': custom_cnn_training_time,\n",
        "            'accuracy': custom_cnn_accuracy,\n",
        "            'precision': custom_cnn_precision,\n",
        "            'recall': custom_cnn_recall,\n",
        "            'f1_score': custom_cnn_f1\n",
        "        },\n",
        "        \n",
        "        # Transfer Learning Results\n",
        "        'transfer_learning': {\n",
        "            'framework': framework_used,\n",
        "            'base_model': pretrained_model_name,\n",
        "            'frozen_layers': frozen_layers,\n",
        "            'trainable_layers': trainable_layers,\n",
        "            'has_global_average_pooling': True,  # MUST be True\n",
        "            'total_parameters': total_parameters,\n",
        "            'trainable_parameters': trainable_parameters,\n",
        "            'training_config': {\n",
        "                'learning_rate': tl_learning_rate,\n",
        "                'n_epochs': tl_epochs,\n",
        "                'batch_size': tl_batch_size,\n",
        "                'optimizer': tl_optimizer,\n",
        "                'loss_function': 'categorical_crossentropy'\n",
        "            },\n",
        "            'initial_loss': tl_initial_loss,\n",
        "            'final_loss': tl_final_loss,\n",
        "            'training_time_seconds': tl_training_time,\n",
        "            'accuracy': tl_accuracy,\n",
        "            'precision': tl_precision,\n",
        "            'recall': tl_recall,\n",
        "            'f1_score': tl_f1\n",
        "        },\n",
        "        \n",
        "        # Analysis\n",
        "        'analysis': analysis_text,\n",
        "        'analysis_word_count': len(analysis_text.split()),\n",
        "        \n",
        "        # Training Success Indicators\n",
        "        'custom_cnn_loss_decreased': custom_cnn_final_loss < custom_cnn_initial_loss if custom_cnn_initial_loss and custom_cnn_final_loss else False,\n",
        "        'transfer_learning_loss_decreased': tl_final_loss < tl_initial_loss if tl_initial_loss and tl_final_loss else False,\n",
        "    }\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94cec80",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate and print results\n",
        "try:\n",
        "    assignment_results = get_assignment_results() \n",
        "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
        "    print(json.dumps(assignment_results, indent=2))\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n  ERROR generating results: {str(e)}\")\n",
        "    print(\"Please ensure all variables are properly defined\")   "
      ]
    },
    {
      "cell_type": "raw",
      "id": "50657458",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        "ENVIRONMENT VERIFICATION - SCREENSHOT REQUIRED\n",
        "\n",
        "IMPORTANT: Take a screenshot of your environment showing account details\n",
        "\n",
        "For Google Colab:\n",
        "- Click on your profile icon (top right)\n",
        "- Screenshot should show your email/account clearly\n",
        "- Include the entire Colab interface with notebook name visible\n",
        "\n",
        "For BITS Virtual Lab:\n",
        "- Screenshot showing your login credentials/account details\n",
        "- Include the entire interface with your username/session info visible\n",
        "\n",
        "Paste the screenshot below this cell or in a new markdown cell.\n",
        "This helps verify the work was done by you in your environment.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4747e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display system information\n",
        "import platform\n",
        "import sys\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5ae62c",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ENVIRONMENT INFORMATION\")\n",
        "print(\"\\n  REQUIRED: Add screenshot of your Google Colab/BITS Virtual Lab\")\n",
        "print(\"showing your account details in the cell below this one.\")\n",
        "\n",
        "# include the screen shot here"
      ]
    },
    {
      "cell_type": "raw",
      "id": "7e214cf5",
      "metadata": {},
      "source": [
        "\"\"\"\n",
        "FINAL CHECKLIST - VERIFY BEFORE SUBMISSION\n",
        "\n",
        "□ Student information filled at the top (BITS ID, Name, Email)\n",
        "□ Filename is <BITS_ID>_cnn_assignment.ipynb\n",
        "□ All cells executed (Kernel → Restart & Run All)\n",
        "□ All outputs visible\n",
        "□ Custom CNN implemented with Global Average Pooling (NO Flatten+Dense)\n",
        "□ Transfer learning implemented with GAP\n",
        "□ Both models use Keras or PyTorch (NOT from scratch)\n",
        "□ Both models trained with loss tracking (initial_loss and final_loss)\n",
        "□ All 4 metrics calculated for both models\n",
        "□ Primary metric selected and justified\n",
        "□ Analysis written (quality matters, not just word count)\n",
        "□ Visualizations created\n",
        "□ Assignment results JSON printed at the end\n",
        "□ No execution errors in any cell\n",
        "□ File opens without corruption\n",
        "□ Submit ONLY .ipynb file (NO zip, NO data files, NO images)\n",
        "□ Only one submission attempt\n",
        "\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
